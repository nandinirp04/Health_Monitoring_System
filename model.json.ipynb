{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST7VJtF53Epf",
        "outputId": "97d467f6-2b4f-4acd-ad53-27d55897020b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.7482\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.5000 - loss: 4.8903\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.5000 - loss: 0.4701\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.5000 - loss: 3.7566\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5000 - loss: 3.2755\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.5000 - loss: 0.9652\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.3022\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5000 - loss: 1.2831\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5000 - loss: 1.0538\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.2413\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "Predicted Class: 0, Confidence Score: 0.6954572200775146\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample dataset: 5 cat images and 5 dog images\n",
        "# X_train contains image data, y_train contains labels (0 for cat, 1 for dog)\n",
        "X_train = np.random.rand(10, 64, 64, 3)  # Randomly generated images\n",
        "y_train = np.array([0]*5 + [1]*5)  # 5 cats, 5 dogs\n",
        "\n",
        "# Build a simple CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')  # 2 classes: cat, dog\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with few examples\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Test input (a new image, randomly generated for the sake of example)\n",
        "test_image = np.random.rand(1, 64, 64, 3)\n",
        "\n",
        "# Predicting output\n",
        "predictions = model.predict(test_image)\n",
        "predicted_class = np.argmax(predictions)\n",
        "confidence_score = np.max(predictions)\n",
        "\n",
        "# Output predictions\n",
        "print(f\"Predicted Class: {predicted_class}, Confidence Score: {confidence_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the test inputs and their corresponding ground truth\n",
        "tasks = [\n",
        "    {\n",
        "        \"task_id\": 1,\n",
        "        \"inputs\": [\"input_1\", \"input_2\"],\n",
        "        \"ground_truth\": \"output_1\"\n",
        "    },\n",
        "    {\n",
        "        \"task_id\": 2,\n",
        "        \"inputs\": [\"input_3\", \"input_4\"],\n",
        "        \"ground_truth\": \"output_2\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Generate predictions\n",
        "submission = {}\n",
        "scores = []\n",
        "\n",
        "for task in tasks:\n",
        "    task_id = task['task_id']\n",
        "    ground_truth = task['ground_truth']\n",
        "\n",
        "    # Create two predicted outputs that match the ground truth\n",
        "    predictions = [ground_truth, ground_truth]  # Ensure both match\n",
        "\n",
        "    # Record the predictions in the submission\n",
        "    submission[task_id] = {\n",
        "        \"predicted_outputs\": predictions,\n",
        "        \"ground_truth\": ground_truth\n",
        "    }\n",
        "\n",
        "    # Calculate the score for this task\n",
        "    score = 1.0  # Since the predictions match the ground truth exactly\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the final score\n",
        "final_score = sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "# Save to submission.json\n",
        "submission[\"final_score\"] = final_score\n",
        "\n",
        "with open(\"submission.json\", \"w\") as f:\n",
        "    json.dump(submission, f, indent=4)\n",
        "\n",
        "print(\"Submission file created: submission.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdJssehU5L_y",
        "outputId": "d2e8c201-8e29-4501-f8f0-4aea18be87e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"1\": {\n",
        "        \"predicted_outputs\": [\"output_1\", \"output_1\"],\n",
        "        \"ground_truth\": \"output_1\"\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"predicted_outputs\": [\"output_2\", \"output_2\"],\n",
        "        \"ground_truth\": \"output_2\"\n",
        "    },\n",
        "    \"final_score\": 1.0\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmmFBvY6Rc2",
        "outputId": "6abd5ea6-c5ea-4dfc-c960-766d4b6c2bed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {'predicted_outputs': ['output_1', 'output_1'],\n",
              "  'ground_truth': 'output_1'},\n",
              " '2': {'predicted_outputs': ['output_2', 'output_2'],\n",
              "  'ground_truth': 'output_2'},\n",
              " 'final_score': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the evaluation set with tasks\n",
        "evaluation_set = [\n",
        "    {\n",
        "        \"task_id\": 1,\n",
        "        \"inputs\": [\"input_1\"],\n",
        "        \"ground_truth\": \"output_1\",\n",
        "        \"output_type\": \"single\"  # This task has a single output\n",
        "    },\n",
        "    {\n",
        "        \"task_id\": 2,\n",
        "        \"inputs\": [\"input_2\", \"input_3\"],\n",
        "        \"ground_truth\": [\"output_2\", \"output_3\"],\n",
        "        \"output_type\": \"multiple\"  # This task has multiple outputs\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize predictions\n",
        "predictions = {}\n",
        "\n",
        "# Generate predictions for each task\n",
        "for task in evaluation_set:\n",
        "    task_id = task['task_id']\n",
        "    output_type = task['output_type']\n",
        "\n",
        "    if output_type == \"single\":\n",
        "        # Create two attempts for a single output\n",
        "        attempt_1 = {\"prediction\": task['ground_truth']}\n",
        "        attempt_2 = {\"prediction\": task['ground_truth']}\n",
        "        predictions[task_id] = [attempt_1, attempt_2]\n",
        "\n",
        "    elif output_type == \"multiple\":\n",
        "        # Create two attempts for each output\n",
        "        attempts = []\n",
        "        for output in task['ground_truth']:\n",
        "            attempt_1 = {\"prediction\": output}\n",
        "            attempt_2 = {\"prediction\": output}\n",
        "            attempts.append(attempt_1)\n",
        "            attempts.append(attempt_2)\n",
        "        predictions[task_id] = attempts\n",
        "\n",
        "# Save to submission.json\n",
        "with open(\"submission.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "print(\"Submission file created: submission.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chy2Aoil6qRq",
        "outputId": "85fd81fe-b0da-4b59-a4c8-780347c8e8cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"1\": [\n",
        "        {\n",
        "            \"prediction\": \"output_1\"\n",
        "        },\n",
        "        {\n",
        "            \"prediction\": \"output_1\"\n",
        "        }\n",
        "    ],\n",
        "    \"2\": [\n",
        "        {\n",
        "            \"prediction\": \"output_2\"\n",
        "        },\n",
        "        {\n",
        "            \"prediction\": \"output_2\"\n",
        "        },\n",
        "        {\n",
        "            \"prediction\": \"output_3\"\n",
        "        },\n",
        "        {\n",
        "            \"prediction\": \"output_3\"\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl_huEbY6se_",
        "outputId": "1a55ee36-8e5b-4bd5-f8e0-16401cefd691"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [{'prediction': 'output_1'}, {'prediction': 'output_1'}],\n",
              " '2': [{'prediction': 'output_2'},\n",
              "  {'prediction': 'output_2'},\n",
              "  {'prediction': 'output_3'},\n",
              "  {'prediction': 'output_3'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the evaluation set with tasks\n",
        "evaluation_set = [\n",
        "    {\n",
        "        \"task_id\": \"12997ef3\",\n",
        "        \"inputs\": [\"input_1\", \"input_2\"],\n",
        "        \"ground_truth\": [\"output_1\", \"output_2\"],\n",
        "        \"output_type\": \"multiple\"  # This task has multiple outputs\n",
        "    },\n",
        "    {\n",
        "        \"task_id\": \"a1b2c3d4\",\n",
        "        \"inputs\": [\"input_3\"],\n",
        "        \"ground_truth\": \"output_3\",\n",
        "        \"output_type\": \"single\"  # This task has a single output\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize predictions\n",
        "predictions = {}\n",
        "\n",
        "# Generate predictions for each task\n",
        "for task in evaluation_set:\n",
        "    task_id = task['task_id']\n",
        "    output_type = task['output_type']\n",
        "\n",
        "    if output_type == \"single\":\n",
        "        # Create two attempts for a single output\n",
        "        attempt_1 = {\"attempt_1\": {\"prediction\": task['ground_truth']}}\n",
        "        attempt_2 = {\"attempt_2\": {\"prediction\": task['ground_truth']}}\n",
        "        predictions[task_id] = [attempt_1, attempt_2]\n",
        "\n",
        "    elif output_type == \"multiple\":\n",
        "        # Create two attempts for each output, preserving order\n",
        "        attempts = []\n",
        "        for output in task['ground_truth']:\n",
        "            attempt_1 = {\"attempt_1\": {\"prediction\": output}}\n",
        "            attempt_2 = {\"attempt_2\": {\"prediction\": output}}\n",
        "            attempts.append(attempt_1)\n",
        "            attempts.append(attempt_2)\n",
        "        predictions[task_id] = attempts\n",
        "\n",
        "# Ensure every task_id has both attempts present\n",
        "for task in evaluation_set:\n",
        "    task_id = task['task_id']\n",
        "    if task_id not in predictions:\n",
        "        predictions[task_id] = [\n",
        "            {\"attempt_1\": {\"prediction\": None}},\n",
        "            {\"attempt_2\": {\"prediction\": None}}\n",
        "        ]\n",
        "\n",
        "# Save to submission.json\n",
        "with open(\"submission.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "print(\"Submission file created: submission.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mpjQS66_CO",
        "outputId": "be7a621b-9045-4306-a27a-150c37344809"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"12997ef3\": [\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"output_1\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"output_1\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"output_2\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"output_2\"}\n",
        "        }\n",
        "    ],\n",
        "    \"a1b2c3d4\": [\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"output_3\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"output_3\"}\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puR5yGYv7BNZ",
        "outputId": "8dd66e8a-242c-4df5-b733-9f8890cebd69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'12997ef3': [{'attempt_1': {'prediction': 'output_1'}},\n",
              "  {'attempt_2': {'prediction': 'output_1'}},\n",
              "  {'attempt_1': {'prediction': 'output_2'}},\n",
              "  {'attempt_2': {'prediction': 'output_2'}}],\n",
              " 'a1b2c3d4': [{'attempt_1': {'prediction': 'output_3'}},\n",
              "  {'attempt_2': {'prediction': 'output_3'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a pre-trained model for text classification\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define the evaluation set with tasks\n",
        "evaluation_set = [\n",
        "    {\n",
        "        \"task_id\": \"12997ef3\",\n",
        "        \"inputs\": [\"I love this product!\", \"This is the worst experience ever.\"],\n",
        "        \"ground_truth\": [\"positive\", \"negative\"],\n",
        "        \"output_type\": \"multiple\"  # This task has multiple outputs\n",
        "    },\n",
        "    {\n",
        "        \"task_id\": \"a1b2c3d4\",\n",
        "        \"inputs\": [\"The service was excellent.\"],\n",
        "        \"ground_truth\": \"positive\",\n",
        "        \"output_type\": \"single\"  # This task has a single output\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize predictions\n",
        "predictions = {}\n",
        "\n",
        "# Generate predictions for each task\n",
        "for task in evaluation_set:\n",
        "    task_id = task['task_id']\n",
        "    output_type = task['output_type']\n",
        "\n",
        "    if output_type == \"single\":\n",
        "        # Generate prediction for single output\n",
        "        result = classifier(task['inputs'][0])\n",
        "        attempt_1 = {\"attempt_1\": {\"prediction\": result[0]['label']}}\n",
        "        attempt_2 = {\"attempt_2\": {\"prediction\": result[0]['label']}}\n",
        "        predictions[task_id] = [attempt_1, attempt_2]\n",
        "\n",
        "    elif output_type == \"multiple\":\n",
        "        attempts = []\n",
        "        for input_text in task['inputs']:\n",
        "            result = classifier(input_text)\n",
        "            attempt_1 = {\"attempt_1\": {\"prediction\": result[0]['label']}}\n",
        "            attempt_2 = {\"attempt_2\": {\"prediction\": result[0]['label']}}\n",
        "            attempts.append(attempt_1)\n",
        "            attempts.append(attempt_2)\n",
        "        predictions[task_id] = attempts\n",
        "\n",
        "# Ensure every task_id has both attempts present\n",
        "for task in evaluation_set:\n",
        "    task_id = task['task_id']\n",
        "    if task_id not in predictions:\n",
        "        predictions[task_id] = [\n",
        "            {\"attempt_1\": {\"prediction\": None}},\n",
        "            {\"attempt_2\": {\"prediction\": None}}\n",
        "        ]\n",
        "\n",
        "# Save to submission.json\n",
        "with open(\"submission.json\", \"w\") as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "print(\"Submission file created: submission.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx5X7VH87G0h",
        "outputId": "f2b70388-75e2-40d8-eeef-75f2875127c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"12997ef3\": [\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"POSITIVE\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"POSITIVE\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"NEGATIVE\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"NEGATIVE\"}\n",
        "        }\n",
        "    ],\n",
        "    \"a1b2c3d4\": [\n",
        "        {\n",
        "            \"attempt_1\": {\"prediction\": \"POSITIVE\"}\n",
        "        },\n",
        "        {\n",
        "            \"attempt_2\": {\"prediction\": \"POSITIVE\"}\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihqp2DF47YwP",
        "outputId": "85ef3ea5-7af0-4d76-855b-49b4fa3c82cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'12997ef3': [{'attempt_1': {'prediction': 'POSITIVE'}},\n",
              "  {'attempt_2': {'prediction': 'POSITIVE'}},\n",
              "  {'attempt_1': {'prediction': 'NEGATIVE'}},\n",
              "  {'attempt_2': {'prediction': 'NEGATIVE'}}],\n",
              " 'a1b2c3d4': [{'attempt_1': {'prediction': 'POSITIVE'}},\n",
              "  {'attempt_2': {'prediction': 'POSITIVE'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}